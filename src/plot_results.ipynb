{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id     label  morfological_complexity  twittersearch  \\\n",
      "0          1  not_fake                     23.0            1.0   \n",
      "1          2      fake                     28.0          100.0   \n",
      "2          3      fake                     22.0          100.0   \n",
      "3          4      fake                     28.0            6.0   \n",
      "4          5  not_fake                     19.0            0.0   \n",
      "5          6      fake                     27.0          100.0   \n",
      "6          7  not_fake                     25.0            0.0   \n",
      "7          8  not_fake                     29.0           11.0   \n",
      "8          9  not_fake                     21.0            9.0   \n",
      "9         10  not_fake                     24.0           14.0   \n",
      "10        11  not_fake                     22.0            1.0   \n",
      "11        12      fake                     17.0            0.0   \n",
      "12        13      fake                     35.0           33.0   \n",
      "13        14      fake                     25.0          100.0   \n",
      "14        15  not_fake                     23.0          100.0   \n",
      "15        16  not_fake                     28.0            0.0   \n",
      "16        17      fake                     18.0            0.0   \n",
      "17        18      fake                     22.0           43.0   \n",
      "18        19  not_fake                     30.0            0.0   \n",
      "19        20      fake                     23.0          100.0   \n",
      "20        21  not_fake                     20.0          100.0   \n",
      "21        22  not_fake                     21.0           20.0   \n",
      "22        23      fake                     22.0            0.0   \n",
      "23        24  not_fake                     25.0            0.0   \n",
      "24        25      fake                     34.0          100.0   \n",
      "25        26  not_fake                     23.0            0.0   \n",
      "26        27      fake                     26.0            0.0   \n",
      "27        28  not_fake                     25.0            0.0   \n",
      "28        29  not_fake                     33.0           33.0   \n",
      "29        30  not_fake                     24.0            0.0   \n",
      "...      ...       ...                      ...            ...   \n",
      "15149  15544       NaN                      NaN            0.0   \n",
      "15150  15545       NaN                      NaN            0.0   \n",
      "15151  15546       NaN                      NaN            0.0   \n",
      "15152  15547       NaN                      NaN            0.0   \n",
      "15153  15548       NaN                      NaN           96.0   \n",
      "15154  15549       NaN                      NaN            1.0   \n",
      "15155  15550       NaN                      NaN            0.0   \n",
      "15156  15551       NaN                      NaN            0.0   \n",
      "15157  15552       NaN                      NaN            0.0   \n",
      "15158  15553       NaN                      NaN            0.0   \n",
      "15159  15554       NaN                      NaN            9.0   \n",
      "15160  15555       NaN                      NaN          100.0   \n",
      "15161  15556       NaN                      NaN          100.0   \n",
      "15162  15557       NaN                      NaN            0.0   \n",
      "15163  15558       NaN                      NaN            0.0   \n",
      "15164  15559       NaN                      NaN            0.0   \n",
      "15165  15560       NaN                      NaN          100.0   \n",
      "15166  15561       NaN                      NaN            0.0   \n",
      "15167  15562       NaN                      NaN            0.0   \n",
      "15168  15563       NaN                      NaN            0.0   \n",
      "15169  15564       NaN                      NaN            0.0   \n",
      "15170  15565       NaN                      NaN            0.0   \n",
      "15171  15566       NaN                      NaN          100.0   \n",
      "15172  15567       NaN                      NaN          100.0   \n",
      "15173  15568       NaN                      NaN            0.0   \n",
      "15174  15569       NaN                      NaN          100.0   \n",
      "15175  15570       NaN                      NaN            5.0   \n",
      "15176  15571       NaN                      NaN           20.0   \n",
      "15177  15572       NaN                      NaN            2.0   \n",
      "15178    786      fake                      NaN            NaN   \n",
      "\n",
      "       lexical_variety  \n",
      "0             0.539250  \n",
      "1             0.454186  \n",
      "2             0.445242  \n",
      "3             0.642857  \n",
      "4             0.650246  \n",
      "5             0.562372  \n",
      "6             0.496350  \n",
      "7             0.356250  \n",
      "8             0.384217  \n",
      "9             0.412795  \n",
      "10            0.512796  \n",
      "11            0.587583  \n",
      "12            0.611765  \n",
      "13            0.293682  \n",
      "14            0.430346  \n",
      "15            0.423323  \n",
      "16            0.579909  \n",
      "17            0.419808  \n",
      "18            0.575472  \n",
      "19            0.607427  \n",
      "20            0.607639  \n",
      "21            0.601942  \n",
      "22            0.520661  \n",
      "23            0.439173  \n",
      "24            0.455137  \n",
      "25            0.498031  \n",
      "26            0.585526  \n",
      "27            0.432718  \n",
      "28            0.311841  \n",
      "29            0.464029  \n",
      "...                ...  \n",
      "15149              NaN  \n",
      "15150              NaN  \n",
      "15151              NaN  \n",
      "15152              NaN  \n",
      "15153              NaN  \n",
      "15154              NaN  \n",
      "15155              NaN  \n",
      "15156              NaN  \n",
      "15157              NaN  \n",
      "15158              NaN  \n",
      "15159              NaN  \n",
      "15160              NaN  \n",
      "15161              NaN  \n",
      "15162              NaN  \n",
      "15163              NaN  \n",
      "15164              NaN  \n",
      "15165              NaN  \n",
      "15166              NaN  \n",
      "15167              NaN  \n",
      "15168              NaN  \n",
      "15169              NaN  \n",
      "15170              NaN  \n",
      "15171              NaN  \n",
      "15172              NaN  \n",
      "15173              NaN  \n",
      "15174              NaN  \n",
      "15175              NaN  \n",
      "15176              NaN  \n",
      "15177              NaN  \n",
      "15178         0.000000  \n",
      "\n",
      "[15179 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# scatter plot + box plot (& istogram) per ogni combinazione di features\n",
    "\n",
    "# notebook:\n",
    "# Legge dalla directory out/ tutti i file che ci sono (uno per feature) e mettere insieme tutto in uno stesso file\n",
    "# (sicuramente la run di twitter andra' da sola e avra' un file di out a parte: si vuole unire ai file gia' presenti delle altre features:\n",
    "# pandas.join... Metti tutto in un file solo, e poi fai i vari plot.\n",
    "\n",
    "import os, pandas\n",
    "\n",
    "# files from \"features_exploration\" out (.csv)\n",
    "out_path = \"..\" + os.sep + \"out\" + os.sep\n",
    "dataframes = []\n",
    "features = []\n",
    "\n",
    "# reads file (= features names = column name)\n",
    "for result_file in os.listdir(out_path):\n",
    "    features.append(result_file)\n",
    "    dataframes.append(pandas.read_csv(out_path + result_file))\n",
    "\n",
    "# directory not empty check\n",
    "if len(dataframes) == 0:\n",
    "    print(\"No csv files in \" + out_path)\n",
    "    exit(1)\n",
    "    \n",
    "# joins all data!\n",
    "final_data = dataframes[0]\n",
    "for dataframe in dataframes[1:]:\n",
    "    final_data = pandas.merge(final_data, dataframe, on=\"id\", how=\"outer\")\n",
    "    \n",
    "# picks only id, label and features columns (merge produces junk too)\n",
    "columns = [\"id\", \"label\"]\n",
    "columns.extend(features)\n",
    "\n",
    "print(final_data[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
